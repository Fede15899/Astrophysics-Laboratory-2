{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Science Frame Correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib widget\n",
    "from astropy.io import fits\n",
    "import pickle\n",
    "\n",
    "science_list = np.genfromtxt('./group10_WASP-135_20190803/science/science.list', dtype=str)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing the code on a subset of images\n",
    "In lab we tested our reduction pipeline and tools only on a small subsample of images beacuse of reduced available space on the computer. Now we will use the full sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "science_test_list = science_list[:30] #Nel caso volessimo ridurre basta selezionare solo alcune immagini di science list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Reduction Steps\n",
    "Science **data reduction** includes the following steps:\n",
    "1. Multiplication by GAIN (as always)\n",
    "2. Bias Subtraction\n",
    "3. Division by flat\n",
    "\n",
    "Therefore we have the following **error sources**:\n",
    "1. Readout Noise\n",
    "2. Bias Error\n",
    "3. Flat Error\n",
    "4. Photon Noise\n",
    "\n",
    "In order to procede we load the necessary quantities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prendiamo i dati salvati\n",
    "median_bias = pickle.load(open(\"median_bias.p\", \"rb\"))\n",
    "median_normalized_flat = pickle.load(open(\"median_normalized_flat.p\", \"rb\"))\n",
    "median_normalized_flat_errors = pickle.load(open(\"median_normalized_flat_errors.p\", \"rb\"))\n",
    "\n",
    "# Prendiamo i dati rimanenti dai notebook 01 e 02\n",
    "bias_std = 1.33 # [e] = photoelectrons\n",
    "readout_noise = 7.10 # [e] = photoelectrons\n",
    "gain = 1.91 #[e/ADU] from the header file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the photon noise, we use the method we employed for the flat. The photon noise must be computed **after** removing the bias but **before** correcting for the flat field. In fact the error must be calculated on the actual number of photons received on the detector, not on the photons emitted by the source.\n",
    "\n",
    "The error on the science_debiased is given by the sum in quadrature of the errors:\n",
    "\n",
    "##### Debiased Error\n",
    "$\\sigma_{debiased} = \\sqrt{\\sigma_{rdn}^2 + \\sigma_{bias}^2 + \\sigma_{photon}^2}$\n",
    "\n",
    "The photon noise follows a Poissonian distribution so it is given by the square root of the counts $\\sqrt{\\texttt{science\\_debiased}}$:\n",
    "\n",
    "$\\sigma_{debiased} = \\sqrt{\\sigma_{rdn}^2 + \\sigma_{bias}^2 + \\texttt{science\\_debiased}}$\n",
    "\n",
    "##### Corrected Error\n",
    "For science correction, the corrected intensity is given by:\n",
    "\n",
    "$\\text{science\\_corrected} = \\frac{\\text{science\\_debiased}}{\\text{median\\_normalized\\_flat}}$\n",
    "\n",
    "We apply the error propagation rule for division. If a quantity $z$ is given by the ratio of two variables $x$ and $y$,\n",
    "\n",
    "$\\frac{\\sigma_z}{z} = \\sqrt{\\left(\\frac{\\sigma_x}{x}\\right)^2 + \\left(\\frac{\\sigma_y}{y}\\right)^2}$\n",
    "\n",
    "Applying this formula to our variables:\n",
    "\n",
    "$\\frac{\\sigma_{\\text{science\\_corrected}}}{\\text{science\\_corrected}} =\n",
    "\\sqrt{\\left(\\frac{\\sigma_{\\text{science\\_debiased}}}{\\text{science\\_debiased}}\\right)^2 +\n",
    "\\left(\\frac{\\sigma_{\\text{median\\_normalized\\_flat}}}{\\text{median\\_normalized\\_flat}}\\right)^2}$\n",
    "\n",
    "Finally, multiplying both sides by $\\text{science\\_corrected}$, we obtain the final expression:\n",
    "\n",
    "$\\sigma_{\\text{science\\_corrected}} =\n",
    "\\text{science\\_corrected} \\times \\sqrt{\n",
    "\\left(\\frac{\\sigma_{\\text{science\\_debiased}}}{\\text{science\\_debiased}}\\right)^2 +\n",
    "\\left(\\frac{\\sigma_{\\text{median\\_normalized\\_flat}}}{\\text{median\\_normalized\\_flat}}\\right)^2\n",
    "}$\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lorenzo\\AppData\\Local\\Temp\\ipykernel_1632\\808184146.py:9: RuntimeWarning: divide by zero encountered in divide\n",
      "  science_corrected = science_debiased / median_normalized_flat # Correggo per il flat\n",
      "C:\\Users\\Lorenzo\\AppData\\Local\\Temp\\ipykernel_1632\\808184146.py:9: RuntimeWarning: invalid value encountered in divide\n",
      "  science_corrected = science_debiased / median_normalized_flat # Correggo per il flat\n",
      "C:\\Users\\Lorenzo\\AppData\\Local\\Temp\\ipykernel_1632\\808184146.py:12: RuntimeWarning: divide by zero encountered in divide\n",
      "  science_corrected_errors = science_corrected * np.sqrt((science_debiased_errors/science_debiased)**2 + (median_normalized_flat_errors/median_normalized_flat)**2)\n",
      "C:\\Users\\Lorenzo\\AppData\\Local\\Temp\\ipykernel_1632\\808184146.py:12: RuntimeWarning: invalid value encountered in multiply\n",
      "  science_corrected_errors = science_corrected * np.sqrt((science_debiased_errors/science_debiased)**2 + (median_normalized_flat_errors/median_normalized_flat)**2)\n"
     ]
    }
   ],
   "source": [
    "for science_name in science_list:\n",
    "    \"\"\"Load the science frames, multiply them by the gain, subtract the median_bias,\n",
    "    divide by the flat. Next we compute the errors.\"\"\"\n",
    "    science_fits = fits.open('./group10_WASP-135_20190803/science/' + science_name)\n",
    "    science_data = science_fits[0].data * gain\n",
    "    science_fits.close()\n",
    "\n",
    "    science_debiased = science_data - median_bias # Sottraggo il bias\n",
    "    science_corrected = science_debiased / median_normalized_flat # Correggo per il flat\n",
    "    \n",
    "    science_debiased_errors = np.sqrt(readout_noise**2 + bias_std**2 + science_debiased)\n",
    "    science_corrected_errors = science_corrected * np.sqrt((science_debiased_errors/science_debiased)**2 + (median_normalized_flat_errors/median_normalized_flat)**2)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving the images\n",
    "\n",
    "We created a new directory $\\texttt{correct}$ where to store the new files. We want to use the same name of the files for our new frames, without the .fits extension.\n",
    "\".fits\" is 5 characters, we can take the strin identifying each file name and remove the last five characters and add the new ones which will be $\\texttt{\\_corr.p}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Esempio\n",
    "# new_name = './correct' + science_name[:-5] + '_corr.p'\n",
    "# print(science_name)\n",
    "# print(science_name[:-5])\n",
    "# new_name = science_name[:-5] + '_corr.p'\n",
    "# print(new_name)\n",
    "\n",
    "for science_name in science_test_list:\n",
    "    new_name = './group10_WASP-135_20190803/correct/' + science_name[:-5] + '_corr.p'\n",
    "    pickle.dump(science_corrected, open(new_name, 'wb'))\n",
    "    new_name = './group10_WASP-135_20190803/correct/' + science_name[:-5] + '_corr_error.p'\n",
    "    pickle.dump(science_corrected_errors, open(new_name, 'wb'))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting and saving useful information\n",
    "We also need to know when the data was taken and some extra information regarding the pointing of the telescope.\n",
    "1. epoch of exposure in Julian Date\n",
    "2. exposure time (duration)\n",
    "3. airmass during the exposure\n",
    "4. filter used for all observations\n",
    "\n",
    "We can gather this information from the header of the fits files.\n",
    "\n",
    "We also need Hour Angle and Declination for further corrections.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " JD at start\n",
      " [s] Exposure time\n",
      " Telescope airmass at start\n"
     ]
    }
   ],
   "source": [
    "n_images = len(science_test_list) # Estraggo numero di immagini\n",
    "\n",
    "# Inizializzo degli array con un entrata per immagine nei quali immagazzinare jd, exptime e airmass\n",
    "array_jd = np.zeros(n_images)\n",
    "array_exptime = np.zeros(n_images)\n",
    "array_airmass = np.zeros(n_images)\n",
    "\n",
    "for i, science_name in enumerate(science_test_list):\n",
    "\n",
    "    \"\"\"In questo ciclo for carico uno ad uno i file .fits della cartella science.\n",
    "    Dall'header di ciascun file ottengo jd, exptime e airmass e relative unità di\n",
    "    misura (solo per il primo file, poi per gli altri sono uguali)\n",
    "     e le salvo negli array.\"\"\"\n",
    "\n",
    "    science_fits = fits.open('./group10_WASP-135_20190803/science/' + science_name)\n",
    "    array_jd[i] = science_fits[0].header['JD']\n",
    "    array_exptime[i] = science_fits[0].header['EXPTIME']\n",
    "    array_airmass[i] = science_fits[0].header['AIRMASS']\n",
    "\n",
    "    # Le unità di misura stanno nei commenti dell'header\n",
    "    if i == 0:\n",
    "        print('',science_fits[0].header.comments['JD'])\n",
    "        print('',science_fits[0].header.comments['EXPTIME'])\n",
    "        print('',science_fits[0].header.comments['AIRMASS'])\n",
    "\n",
    "    science_fits.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conversion to BJD_TDB\n",
    "\n",
    "We have saved the Jd of the observation, however, what we really want id the time as recorded at the Barycenter of the Solar System, as we do not want to be influenced by the specific position of the observatory when the observations are taken.\n",
    "\n",
    "When observing a celestial object from Earth, our planet moves around the Solar System barycenter, which is not exactly at the Sun's center due to the influence of massive planets like Jupiter and Saturn.\n",
    "\n",
    "As a result, the time at which light from an object reaches our telescope depends on Earth's position in its orbit. Observing the same star at different times of the year means the light travel time to Earth varies slightly.\n",
    "\n",
    "If we do not correct for this effect, the recorded observation time may have an error of up to ±8 minutes (about 500 seconds), which corresponds to the time light takes to cross Earth's orbit.\n",
    "\n",
    "Using the **Barycentric Julian Date (BJD_TDB)** ensures that all observations are referenced to the same point in space: the **Solar System barycenter**. This removes the effect of Earth's motion and makes observation times comparable across different observatories.\n",
    "\n",
    "This correction is essential regardless of the observed object (a nearby star, a distant galaxy, or an exoplanet). It ensures we refer to the actual time when the light left the source, rather than when it was received on Earth.\n",
    "\n",
    "For consistency, if observations were recorded from another planet (e.g., Mars), using BJD_TDB would allow direct comparison with data from Earth, as all timestamps would be referenced to the same spatial point.\n",
    "\n",
    "##### Steps in BJD_TDB Correction  \n",
    "\n",
    "1. **Mid-Exposure Correction**  \n",
    "   Observations are timestamped at the start of the exposure, but we need the mid-exposure time for accuracy. This is done by adding half the exposure duration to the initial Julian Date.  \n",
    "\n",
    "2. **UTC to TDB Conversion**  \n",
    "   UTC is affected by leap seconds, making it discontinuous. We convert to **Barycentric Dynamical Time (TDB)**, a continuous timescale used for precise astronomical calculations.  \n",
    "\n",
    "3. **Light Travel Time Correction**  \n",
    "   Light takes time to reach Earth, and the exact arrival time depends on Earth's position in its orbit. We correct for this delay by referencing the observation time to the **Solar System Barycenter (SSB)**, ensuring consistency across different epochs and locations.  \n",
    "\n",
    "We use the $\\texttt{Time}$ package to perform these calculations. We need to specify our coordinate system and our position as well. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "science00_fits = fits.open('./group10_WASP-135_20190803/science/' + science_list[0])\n",
    "# The primary HDU is stored into the first place in the fits file.\n",
    "science00_hdu = science00_fits[0]\n",
    "#The header contains a lot of information regarding the fits file.\n",
    "science00_hdu.header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from astropy import coordinates as coord\n",
    "from astropy import units as u\n",
    "\n",
    "# LST     = '17:20:02.0'         / Local sideral time at start                    \n",
    "# HA      = '-00:29:56'          / Telescope HA at start                          \n",
    "# RA      = '17:49:12.93'        / Telescope RA (J2000.0)                         \n",
    "# DEC     = '+29:52:48'          / Telescope DEC (J2000.0) \n",
    "\n",
    "target = coord.SkyCoord(\"20:13:31.61\",\"+65:09:43.49\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
