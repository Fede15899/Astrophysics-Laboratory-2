{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Science Frame Correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib widget\n",
    "from astropy.io import fits\n",
    "import pickle\n",
    "\n",
    "science_list = np.genfromtxt('./group10_WASP-135_20190803/science/science.list', dtype=str)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing the code on a subset of images\n",
    "In lab we tested our reduction pipeline and tools only on a small subsample of images beacuse of reduced available space on the computer. Now we will use the full sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "science_test_list = science_list[:30] #Nel caso volessimo ridurre basta selezionare solo alcune immagini di science list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Reduction Steps\n",
    "Science **data reduction** includes the following steps:\n",
    "1. Multiplication by GAIN (as always)\n",
    "2. Bias Subtraction\n",
    "3. Division by flat\n",
    "\n",
    "Therefore we have the following **error sources**:\n",
    "1. Readout Noise\n",
    "2. Bias Error\n",
    "3. Flat Error\n",
    "4. Photon Noise\n",
    "\n",
    "In order to procede we load the necessary quantities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prendiamo i dati salvati\n",
    "median_bias = pickle.load(open(\"median_bias.p\", \"rb\"))\n",
    "median_normalized_flat = pickle.load(open(\"median_normalized_flat.p\", \"rb\"))\n",
    "median_normalized_flat_errors = pickle.load(open(\"median_normalized_flat_errors.p\", \"rb\"))\n",
    "\n",
    "# Prendiamo i dati rimanenti dai notebook 01 e 02\n",
    "bias_std = 1.33 # [e] = photoelectrons\n",
    "readout_noise = 7.10 # [e] = photoelectrons\n",
    "gain = 1.91 #[e/ADU] from the header file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the photon noise, we use the method we employed for the flat. The photon noise must be computed **after** removing the bias but **before** correcting for the flat field. In fact the error must be calculated on the actual number of photons received on the detector, not on the photons emitted by the source.\n",
    "\n",
    "The error on the science_debiased is given by the sum in quadrature of the errors:\n",
    "\n",
    "##### Debiased Error\n",
    "$\\sigma_{debiased} = \\sqrt{\\sigma_{rdn}^2 + \\sigma_{bias}^2 + \\sigma_{photon}^2}$\n",
    "\n",
    "The photon noise follows a Poissonian distribution so it is given by the square root of the counts $\\sqrt{\\texttt{science\\_debiased}}$:\n",
    "\n",
    "$\\sigma_{debiased} = \\sqrt{\\sigma_{rdn}^2 + \\sigma_{bias}^2 + \\texttt{science\\_debiased}}$\n",
    "\n",
    "##### Corrected Error\n",
    "For science correction, the corrected intensity is given by:\n",
    "\n",
    "$\\text{science\\_corrected} = \\frac{\\text{science\\_debiased}}{\\text{median\\_normalized\\_flat}}$\n",
    "\n",
    "We apply the error propagation rule for division. If a quantity $z$ is given by the ratio of two variables $x$ and $y$,\n",
    "\n",
    "$\\frac{\\sigma_z}{z} = \\sqrt{\\left(\\frac{\\sigma_x}{x}\\right)^2 + \\left(\\frac{\\sigma_y}{y}\\right)^2}$\n",
    "\n",
    "Applying this formula to our variables:\n",
    "\n",
    "$\\frac{\\sigma_{\\text{science\\_corrected}}}{\\text{science\\_corrected}} =\n",
    "\\sqrt{\\left(\\frac{\\sigma_{\\text{science\\_debiased}}}{\\text{science\\_debiased}}\\right)^2 +\n",
    "\\left(\\frac{\\sigma_{\\text{median\\_normalized\\_flat}}}{\\text{median\\_normalized\\_flat}}\\right)^2}$\n",
    "\n",
    "Finally, multiplying both sides by $\\text{science\\_corrected}$, we obtain the final expression:\n",
    "\n",
    "$\\sigma_{\\text{science\\_corrected}} =\n",
    "\\text{science\\_corrected} \\times \\sqrt{\n",
    "\\left(\\frac{\\sigma_{\\text{science\\_debiased}}}{\\text{science\\_debiased}}\\right)^2 +\n",
    "\\left(\\frac{\\sigma_{\\text{median\\_normalized\\_flat}}}{\\text{median\\_normalized\\_flat}}\\right)^2\n",
    "}$\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lorenzo\\AppData\\Local\\Temp\\ipykernel_1632\\808184146.py:9: RuntimeWarning: divide by zero encountered in divide\n",
      "  science_corrected = science_debiased / median_normalized_flat # Correggo per il flat\n",
      "C:\\Users\\Lorenzo\\AppData\\Local\\Temp\\ipykernel_1632\\808184146.py:9: RuntimeWarning: invalid value encountered in divide\n",
      "  science_corrected = science_debiased / median_normalized_flat # Correggo per il flat\n",
      "C:\\Users\\Lorenzo\\AppData\\Local\\Temp\\ipykernel_1632\\808184146.py:12: RuntimeWarning: divide by zero encountered in divide\n",
      "  science_corrected_errors = science_corrected * np.sqrt((science_debiased_errors/science_debiased)**2 + (median_normalized_flat_errors/median_normalized_flat)**2)\n",
      "C:\\Users\\Lorenzo\\AppData\\Local\\Temp\\ipykernel_1632\\808184146.py:12: RuntimeWarning: invalid value encountered in multiply\n",
      "  science_corrected_errors = science_corrected * np.sqrt((science_debiased_errors/science_debiased)**2 + (median_normalized_flat_errors/median_normalized_flat)**2)\n"
     ]
    }
   ],
   "source": [
    "for science_name in science_list:\n",
    "    \"\"\"Load the science frames, multiply them by the gain, subtract the median_bias,\n",
    "    divide by the flat. Next we compute the errors.\"\"\"\n",
    "    science_fits = fits.open('./group10_WASP-135_20190803/science/' + science_name)\n",
    "    science_data = science_fits[0].data * gain\n",
    "    science_fits.close()\n",
    "\n",
    "    science_debiased = science_data - median_bias # Sottraggo il bias\n",
    "    science_corrected = science_debiased / median_normalized_flat # Correggo per il flat\n",
    "    \n",
    "    science_debiased_errors = np.sqrt(readout_noise**2 + bias_std**2 + science_debiased)\n",
    "    science_corrected_errors = science_corrected * np.sqrt((science_debiased_errors/science_debiased)**2 + (median_normalized_flat_errors/median_normalized_flat)**2)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving the images\n",
    "\n",
    "We created a new directory $\\texttt{correct}$ where to store the new files. We want to use the same name of the files for our new frames, without the .fits extension.\n",
    "\".fits\" is 5 characters, we can take the strin identifying each file name and remove the last five characters and add the new ones which will be $\\texttt{\\_corr.p}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Esempio\n",
    "# new_name = './correct' + science_name[:-5] + '_corr.p'\n",
    "# print(science_name)\n",
    "# print(science_name[:-5])\n",
    "# new_name = science_name[:-5] + '_corr.p'\n",
    "# print(new_name)\n",
    "\n",
    "for science_name in science_test_list:\n",
    "    new_name = './group10_WASP-135_20190803/correct/' + science_name[:-5] + '_corr.p'\n",
    "    pickle.dump(science_corrected, open(new_name, 'wb'))\n",
    "    new_name = './group10_WASP-135_20190803/correct/' + science_name[:-5] + '_corr_error.p'\n",
    "    pickle.dump(science_corrected_errors, open(new_name, 'wb'))\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
