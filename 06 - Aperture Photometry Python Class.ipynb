{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Class Tutorial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as colors\n",
    "import pickle \n",
    "from astropy.io import fits\n",
    "%matplotlib widget"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use a class to define several functions in a self-consistent way repeatedly and be able to use them in different notebooks without rewriting them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Class Objects\n",
    "Class objects support two kind of operations: *attribute references* and *instantiation*. **Attribute references** use the standard syntax in python (obj.name)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12345\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Hello World'"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example:\n",
    "class MyClass:\n",
    "    \"\"\"A simple example class\"\"\"\n",
    "    internal_variable = 12345\n",
    "\n",
    "    def print_hello(self):\n",
    "        return 'Hello World'\n",
    "\n",
    "# To retrieve the value of the internal variable we use:\n",
    "print(MyClass.internal_variable)\n",
    "# To use the function of the class we use\n",
    "MyClass.print_hello(MyClass)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The argument $\\texttt{self}$ of the class means that the function requires the class itself as an argument.\n",
    "\n",
    "**Class instantiation** uses function notation. We can create a new instance of the class and assign his object to a local variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first_class internal variable value: 12345\n",
      "second_class internal variable value: 67890\n"
     ]
    }
   ],
   "source": [
    "first_class = MyClass()\n",
    "second_class = MyClass()\n",
    "# We have two objects of type MyClass with all the attributes and functions\n",
    "# of the original class but will work independently\n",
    "\n",
    "second_class.internal_variable = 67890\n",
    "print('first_class internal variable value:', first_class.internal_variable)\n",
    "print('second_class internal variable value:', second_class.internal_variable)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A variable inside a class takes the name of **attribute** while functions are called **methods**. When calling a method of an instance object you don0t need to specify the self argument"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hello World'"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MyClass.print_hello(MyClass) #Here I need the self argument\n",
    "second_class.print_hello() #Here I don't need it, notice the difference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Class Initialization\n",
    "Classes support a special kind of method that is automatically called **every time** you create a new class instance. This inizialization method is defined by the name ```__init__```. When we create a new object using our class, the init method is automatically invoked. In the following example init requires two arguments other than the self one, so we have to provide them to avoid an error "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MySecondClass:\n",
    "    def __init__(self, x_input, y_input):\n",
    "        self.x_pos = x_input\n",
    "        self.y_pos = y_input\n",
    "\n",
    "#new_class = MySecondClass() -> WRONG! No arguments\n",
    "new_class = MySecondClass(258, 76) # Correct"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we change the class, we have to make a new instance, the previous one won't be updated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attributes called from a class method 260 76\n",
      "attributes called from instance object: 258 76\n"
     ]
    }
   ],
   "source": [
    "class MySecondClass:\n",
    "    def __init__(self, x_input, y_input):\n",
    "        self.x_pos = x_input\n",
    "        self.y_pos = y_input\n",
    "\n",
    "    def print_position(self):\n",
    "        print('Attributes called from a class method', self.x_pos, self.y_pos)\n",
    "\n",
    "    def change_position(self, x_new, y_new):\n",
    "        self.x_pos = x_new\n",
    "        self.y_pos = y_new\n",
    "\n",
    "newest_class = MySecondClass(260, 76)\n",
    "newest_class.print_position()\n",
    "\n",
    "print('attributes called from instance object:', new_class.x_pos, new_class.y_pos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can write a method to change one or more attributes. The method must get ```self``` as the argument, and the attributes to be changed must be referenced as ```self```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "789 123\n"
     ]
    }
   ],
   "source": [
    "class MySecondClass:\n",
    "\n",
    "    def change_position(self, x_new, y_new):\n",
    "        self.x_pos = x_new\n",
    "        self.y_pos = y_new\n",
    "\n",
    "    \"\"\"def wrong_method(x_new, y_new):\n",
    "        x_pos = x_new\n",
    "        y_pos = y_new\"\"\"\n",
    "    \n",
    "    \"\"\"All the methods called after the change_position will use the updated\n",
    "    values for self.x_pos and self.y_pos\"\"\"\n",
    "\n",
    "new_class = MySecondClass()\n",
    "new_class.change_position(789, 123)\n",
    "print(new_class.x_pos, new_class.y_pos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aperture Photometry Class\n",
    "Let's make our class to perform aperture photometry with different apertures and on several stars effortlessly. The complete code will be exported in a .py file for further use.\n",
    "\n",
    "### Initialization\n",
    "As this is a work in progress, we will call our class ```TemporaryAperturePhotometry``` for now. We provide some constants that will be the same regardless of the star under analysis (given that we use the same frames).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['AF559481.fits' 'AF559482.fits' 'AF559483.fits' 'AF559484.fits'\n",
      " 'AF559485.fits' 'AF559486.fits' 'AF559487.fits' 'AF559488.fits'\n",
      " 'AF559489.fits' 'AF559490.fits']\n"
     ]
    }
   ],
   "source": [
    "class TemporaryAperturePhotometry:\n",
    "    def __init__(self):\n",
    "        \n",
    "        self.data_path = './group10_WASP-135_20190803/'\n",
    "\n",
    "        # Constants from HEADER file\n",
    "        self.readout_noise = 7.10 # [e] photoelectrons\n",
    "        self.gain = 1.91 # [e] photoelectrons\n",
    "\n",
    "        # Computed in 01 - Bias Analysis.ipynb\n",
    "        self.bias_std = 1.33 # [e] = photoelectrons\n",
    "        self.median_bias = pickle.load(open('./median_bias.p', 'rb'))\n",
    "        self.median_bias_error_distribution = pickle.load(open('./median_bias_error.p', 'rb'))\n",
    "        # We chose to use the specific value in lecture 01\n",
    "        self.median_bias_error_value = pickle.load(open('./median_bias_error_value.p', 'rb'))\n",
    "\n",
    "        # Computed in 02 - Flat Analysis.ipynb\n",
    "        self.median_normalized_flat = pickle.load(open('./median_normalized_flat.p', 'rb'))\n",
    "        self.median_normalized_flat_error = pickle.load(open('./median_normalized_flat_errors.p', 'rb'))\n",
    "\n",
    "        # Computed in 03 - Science Analysis.ipynb\n",
    "        self.science_path = self.data_path + 'science/'\n",
    "        self.science_list = np.genfromtxt(self.science_path + 'science.list', dtype = str)\n",
    "        self.science_size = len(self.science_list)\n",
    "\n",
    "target_star = TemporaryAperturePhotometry()\n",
    "print(target_star.science_list[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the calibration files (bias, flat) and the science files have the same size, we can define here the meshgrid arrays used later on to compute the distance of each pixel from our star."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TemporaryAperturePhotometry:\n",
    "    def __init__(self):\n",
    "        \n",
    "        self.data_path = './group10_WASP-135_20190803/'\n",
    "\n",
    "        # Constants from HEADER file\n",
    "        self.readout_noise = 7.10 # [e] photoelectrons\n",
    "        self.gain = 1.91 # [e] photoelectrons\n",
    "\n",
    "        # Computed in 01 - Bias Analysis.ipynb\n",
    "        self.bias_std = 1.33 # [e] = photoelectrons\n",
    "        self.median_bias = pickle.load(open('./median_bias.p', 'rb'))\n",
    "        self.median_bias_error_distribution = pickle.load(open('./median_bias_error.p', 'rb'))\n",
    "        # We chose to use the specific value in lecture 01\n",
    "        self.median_bias_error_value = pickle.load(open('./median_bias_error_value.p', 'rb'))\n",
    "\n",
    "        # Computed in 02 - Flat Analysis.ipynb\n",
    "        self.median_normalized_flat = pickle.load(open('./median_normalized_flat.p', 'rb'))\n",
    "        self.median_normalized_flat_error = pickle.load(open('./median_normalized_flat_errors.p', 'rb'))\n",
    "\n",
    "        # Computed in 03 - Science Analysis.ipynb\n",
    "        self.science_path = self.data_path + 'science/'\n",
    "        self.science_list = np.genfromtxt(self.science_path + 'science.list', dtype = str)\n",
    "        self.science_size = len(self.science_list)\n",
    "\n",
    "        # Meshgrid Definition (remember to swap x and y)\n",
    "        ylen, xlen = np.shape(self.median_bias)\n",
    "        X_axis = np.arange(0, xlen, 1)\n",
    "        Y_axis = np.arange(0, ylen, 1)\n",
    "        # Only the meshgrid arrays are stored as attributes, we don't need the intermediate steps\n",
    "        self.X, self.Y = np.meshgrid(X_axis, Y_axis)\n",
    "\n",
    "target_star = TemporaryAperturePhotometry()\n",
    "#Check del funzionamento\n",
    "#print(target_star.X, target_star.Y) # Funziona\n",
    "#print(target_star.median_bias_error_distribution, target_star.median_bias_error_value) # Funziona\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining the ```aperture_photometry``` method\n",
    "We start with an empty function and we slowly fill it with all the operations we have done during the previous lectures, starting from ```03 - Science Analysis.ipynb```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TemporaryAperturePhotometry:\n",
    "    def __init__(self):\n",
    "        \n",
    "        self.data_path = './group10_WASP-135_20190803/'\n",
    "\n",
    "        # Constants from HEADER file\n",
    "        self.readout_noise = 7.10 # [e] photoelectrons\n",
    "        self.gain = 1.91 # [e] photoelectrons\n",
    "\n",
    "        # Computed in 01 - Bias Analysis.ipynb\n",
    "        self.bias_std = 1.33 # [e] = photoelectrons\n",
    "        self.median_bias = pickle.load(open('./median_bias.p', 'rb'))\n",
    "        self.median_bias_error_distribution = pickle.load(open('./median_bias_error.p', 'rb'))\n",
    "        # We chose to use the specific value in lecture 01\n",
    "        self.median_bias_error_value = pickle.load(open('./median_bias_error_value.p', 'rb'))\n",
    "\n",
    "        # Computed in 02 - Flat Analysis.ipynb\n",
    "        self.median_normalized_flat = pickle.load(open('./median_normalized_flat.p', 'rb'))\n",
    "        self.median_normalized_flat_error = pickle.load(open('./median_normalized_flat_errors.p', 'rb'))\n",
    "\n",
    "        # Computed in 03 - Science Analysis.ipynb\n",
    "        self.science_path = self.data_path + 'science/'\n",
    "        self.science_list = np.genfromtxt(self.science_path + 'science.list', dtype = str)\n",
    "        self.science_size = len(self.science_list)\n",
    "\n",
    "        # Meshgrid Definition (remember to swap x and y)\n",
    "        ylen, xlen = np.shape(self.median_bias)\n",
    "        X_axis = np.arange(0, xlen, 1)\n",
    "        Y_axis = np.arange(0, ylen, 1)\n",
    "        # Only the meshgrid arrays are stored as attributes, we don't need the intermediate steps\n",
    "        self.X, self.Y = np.meshgrid(X_axis, Y_axis)\n",
    "\n",
    "    def aperture_photometry(self):\n",
    "        for i, science_name in enumerate(self.science_list):\n",
    "            # Open the i-th fits file\n",
    "            science_fits = fits.open(self.science_path +  science_name)\n",
    "            # Save the i-th flux in science_data\n",
    "            science_data = science_fits[0].data * self.gain # Viene sovrascritto ad ogni iterazione quindi va salvato prima della fine del ciclo\n",
    "            science_fits.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extracting information from the header\n",
    "Since we are opening our science fits file, this is the moment to retrieve and store all the information we need from the header.\n",
    "1. Outside the cycle we create an empty array with size equal to the number of frames for each information we have to store\n",
    "2. Inside the cycle we have to populate thos arrays. We have to read the header before closing the fits file and we have to store the information as class *attributes* in order to be able to use them in other functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TemporaryAperturePhotometry:\n",
    "    def __init__(self):\n",
    "        \n",
    "        self.data_path = './group10_WASP-135_20190803/'\n",
    "\n",
    "        # Constants from HEADER file\n",
    "        self.readout_noise = 7.10 # [e] photoelectrons\n",
    "        self.gain = 1.91 # [e] photoelectrons\n",
    "\n",
    "        # Computed in 01 - Bias Analysis.ipynb\n",
    "        self.bias_std = 1.33 # [e] = photoelectrons\n",
    "        self.median_bias = pickle.load(open('./median_bias.p', 'rb'))\n",
    "        self.median_bias_error_distribution = pickle.load(open('./median_bias_error.p', 'rb'))\n",
    "        # We chose to use the specific value in lecture 01\n",
    "        self.median_bias_error_value = pickle.load(open('./median_bias_error_value.p', 'rb'))\n",
    "\n",
    "        # Computed in 02 - Flat Analysis.ipynb\n",
    "        self.median_normalized_flat = pickle.load(open('./median_normalized_flat.p', 'rb'))\n",
    "        self.median_normalized_flat_error = pickle.load(open('./median_normalized_flat_errors.p', 'rb'))\n",
    "\n",
    "        # Computed in 03 - Science Analysis.ipynb\n",
    "        self.science_path = self.data_path + 'science/'\n",
    "        self.science_list = np.genfromtxt(self.science_path + 'science.list', dtype = str)\n",
    "        self.science_size = len(self.science_list)\n",
    "\n",
    "        # Meshgrid Definition (remember to swap x and y)\n",
    "        ylen, xlen = np.shape(self.median_bias)\n",
    "        X_axis = np.arange(0, xlen, 1)\n",
    "        Y_axis = np.arange(0, ylen, 1)\n",
    "        # Only the meshgrid arrays are stored as attributes, we don't need the intermediate steps\n",
    "        self.X, self.Y = np.meshgrid(X_axis, Y_axis)\n",
    "\n",
    "    def aperture_photometry(self):\n",
    "\n",
    "\n",
    "        # Array Initialization\n",
    "        self.airmass = np.empty(self.science_size)\n",
    "        self.exptime = np.empty(self.science_size)\n",
    "        self.julian_date = np.epmty(self.science_size)\n",
    "\n",
    "\n",
    "        for i, science_name in enumerate(self.science_list):\n",
    "            # Open the i-th fits file\n",
    "            science_fits = fits.open(self.science_path +  science_name)\n",
    "\n",
    "            self.airmass[i] = science_fits[0].header['AIRMASS']\n",
    "            self.exptime[i] = science_fits[0].header['EXPTIME']\n",
    "            self.julian_date[i] = science_fits[0].header['JD']\n",
    "\n",
    "            # Save the i-th flux in science_data\n",
    "            science_data = science_fits[0].data * self.gain # Viene sovrascritto ad ogni iterazione quindi va salvato prima della fine del ciclo\n",
    "            science_fits.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have all the information we need, we define a method called ```correct_science_frame``` which corrects the raw science frame in input and gives the corrected science frame and the associated errors in output. Then we use this method inside the ```aperture_photometry``` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TemporaryAperturePhotometry:\n",
    "    def __init__(self):\n",
    "        \n",
    "        self.data_path = './group10_WASP-135_20190803/'\n",
    "\n",
    "        # Constants from HEADER file\n",
    "        self.readout_noise = 7.10 # [e] photoelectrons\n",
    "        self.gain = 1.91 # [e] photoelectrons\n",
    "\n",
    "        # Computed in 01 - Bias Analysis.ipynb\n",
    "        self.bias_std = 1.33 # [e] = photoelectrons\n",
    "        self.median_bias = pickle.load(open('./median_bias.p', 'rb'))\n",
    "        self.median_bias_error_distribution = pickle.load(open('./median_bias_error.p', 'rb'))\n",
    "        # We chose to use the specific value in lecture 01\n",
    "        self.median_bias_error_value = pickle.load(open('./median_bias_error_value.p', 'rb'))\n",
    "\n",
    "        # Computed in 02 - Flat Analysis.ipynb\n",
    "        self.median_normalized_flat = pickle.load(open('./median_normalized_flat.p', 'rb'))\n",
    "        self.median_normalized_flat_error = pickle.load(open('./median_normalized_flat_errors.p', 'rb'))\n",
    "\n",
    "        # Computed in 03 - Science Analysis.ipynb\n",
    "        self.science_path = self.data_path + 'science/'\n",
    "        self.science_list = np.genfromtxt(self.science_path + 'science.list', dtype = str)\n",
    "        self.science_size = len(self.science_list)\n",
    "\n",
    "        # Meshgrid Definition (remember to swap x and y)\n",
    "        ylen, xlen = np.shape(self.median_bias)\n",
    "        X_axis = np.arange(0, xlen, 1)\n",
    "        Y_axis = np.arange(0, ylen, 1)\n",
    "        # Only the meshgrid arrays are stored as attributes, we don't need the intermediate steps\n",
    "        self.X, self.Y = np.meshgrid(X_axis, Y_axis)\n",
    "\n",
    "    def correct_science_frame(self, science_data):\n",
    "        \"\"\" \n",
    "        This function corrects a single science frame by subtracting the bias and\n",
    "        dividing by the flat.\n",
    "\n",
    "        Inputs:\n",
    "        - self: median_bias, median_normalized_flat, readout_noise, bias_std, median_normalized_flat_error, median_normalized_flat.\n",
    "        - science_data: 2D array containing the flux of each pixel of the selected frame.\n",
    "\n",
    "        Returns:\n",
    "        - science_corrected: 2D array containing the flux of each pixel of the corrected science frame.\n",
    "        - science_corrected_error: 2D array containing the error on each pixel of the corrected frame.\n",
    "        \"\"\"\n",
    "        # Correct the frame by subtracting bias and dividing by flat\n",
    "        science_debiased = science_data - self.median_bias\n",
    "        science_corrected = science_debiased /self.median_normalized_flat\n",
    "\n",
    "        # Compute the error on the corrected frame\n",
    "        science_debiased_error = np.sqrt(self.readout_noise**2 + self.bias_std**2 + science_debiased)\n",
    "        science_corrected_error = science_corrected * np.sqrt((science_debiased_error/science_debiased)**2 + (self.median_normalized_flat_error/self.median_normalized_flat)**2)\n",
    "\n",
    "        return science_corrected, science_corrected_error\n",
    "\n",
    "    def aperture_photometry(self):\n",
    "\n",
    "\n",
    "        # Array Initialization\n",
    "        self.airmass = np.empty(self.science_size)\n",
    "        self.exptime = np.empty(self.science_size)\n",
    "        self.julian_date = np.epmty(self.science_size)\n",
    "\n",
    "\n",
    "        for i, science_name in enumerate(self.science_list):\n",
    "            # Open the i-th fits file\n",
    "            science_fits = fits.open(self.science_path +  science_name)\n",
    "\n",
    "            self.airmass[i] = science_fits[0].header['AIRMASS']\n",
    "            self.exptime[i] = science_fits[0].header['EXPTIME']\n",
    "            self.julian_date[i] = science_fits[0].header['JD']\n",
    "\n",
    "            # Save the i-th flux in science_data\n",
    "            science_data = science_fits[0].data * self.gain # Viene sovrascritto ad ogni iterazione quindi va salvato prima della fine del ciclo\n",
    "            science_fits.close()\n",
    "\n",
    "            # Call the method to correct the frame for bias and flat.\n",
    "            science_corrected, science_corrected_error = self.correct_science_frame(science_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Defining sky correction and aperture photometry\n",
    "\n",
    "Before computing the centroid and performing the aperture photometry, we need to provide:\n",
    "1. Sky inner and outer radius to define the annulus for the measurement of the background.\n",
    "2. Aperture_radius for the aperture photometry\n",
    "3. Initial guess for the position of the star, x_initial and y_initial\n",
    "\n",
    "We will define those parameters inside the aperture photometry method.\n",
    "\n",
    "Next we have to incorporate the **Centroid Algorithm**.\n",
    "- We take the algorithm we used in ```04 - Centroid Measurement``` to compute the centroid position and encapsulate it inside a new method\n",
    "- Provide the necessary parameters (science frame, maximum number of iterations, ...)\n",
    "- Return the refined coordinates of the centre."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TemporaryAperturePhotometry:\n",
    "    def __init__(self):\n",
    "        \n",
    "        self.data_path = './group10_WASP-135_20190803/'\n",
    "\n",
    "        # Constants from HEADER file\n",
    "        self.readout_noise = 7.10 # [e] photoelectrons\n",
    "        self.gain = 1.91 # [e] photoelectrons\n",
    "\n",
    "        # Computed in 01 - Bias Analysis.ipynb\n",
    "        self.bias_std = 1.33 # [e] = photoelectrons\n",
    "        self.median_bias = pickle.load(open('./median_bias.p', 'rb'))\n",
    "        self.median_bias_error_distribution = pickle.load(open('./median_bias_error.p', 'rb'))\n",
    "        # We chose to use the specific value in lecture 01\n",
    "        self.median_bias_error_value = pickle.load(open('./median_bias_error_value.p', 'rb'))\n",
    "\n",
    "        # Computed in 02 - Flat Analysis.ipynb\n",
    "        self.median_normalized_flat = pickle.load(open('./median_normalized_flat.p', 'rb'))\n",
    "        self.median_normalized_flat_error = pickle.load(open('./median_normalized_flat_errors.p', 'rb'))\n",
    "\n",
    "        # Computed in 03 - Science Analysis.ipynb\n",
    "        self.science_path = self.data_path + 'science/'\n",
    "        self.science_list = np.genfromtxt(self.science_path + 'science.list', dtype = str)\n",
    "        self.science_size = len(self.science_list)\n",
    "\n",
    "        # Meshgrid Definition (remember to swap x and y)\n",
    "        ylen, xlen = np.shape(self.median_bias)\n",
    "        X_axis = np.arange(0, xlen, 1)\n",
    "        Y_axis = np.arange(0, ylen, 1)\n",
    "        # Only the meshgrid arrays are stored as attributes, we don't need the intermediate steps\n",
    "        self.X, self.Y = np.meshgrid(X_axis, Y_axis)\n",
    "\n",
    "    def correct_science_frame(self, science_data):\n",
    "        \"\"\" \n",
    "        This function corrects a single science frame by subtracting the bias and\n",
    "        dividing by the flat.\n",
    "\n",
    "        Inputs:\n",
    "        - self: median_bias, median_normalized_flat, readout_noise, bias_std, median_normalized_flat_error, median_normalized_flat.\n",
    "        - science_data: 2D array containing the flux of each pixel of the selected frame.\n",
    "\n",
    "        Returns:\n",
    "        - science_corrected: 2D array containing the flux of each pixel of the corrected science frame.\n",
    "        - science_corrected_error: 2D array containing the error on each pixel of the corrected frame.\n",
    "        \"\"\"\n",
    "\n",
    "        # Correct the frame by subtracting bias and dividing by flat\n",
    "        science_debiased = science_data - self.median_bias\n",
    "        science_corrected = science_debiased /self.median_normalized_flat\n",
    "\n",
    "        # Compute the error on the corrected frame\n",
    "        science_debiased_error = np.sqrt(self.readout_noise**2 + self.bias_std**2 + science_debiased)\n",
    "        science_corrected_error = science_corrected * np.sqrt((science_debiased_error/science_debiased)**2 + (self.median_normalized_flat_error/self.median_normalized_flat)**2)\n",
    "\n",
    "        return science_corrected, science_corrected_error\n",
    "\n",
    "    def compute_centroid(self, science_frame, x_target_initial, y_target_initial, max_iterations=20):\n",
    "        \"\"\"       \n",
    "        This function computes the coordinates of the centroid of a selected frame.\n",
    "\n",
    "        Inputs:\n",
    "        - self: attributes of the class.\n",
    "        - science_frame: frame on which to compute the centroid. It should be a science corrected frame.\n",
    "        - x_target_initial: initial estimate of the x coordinate of the centroid.\n",
    "        - y_target_initial: initial estimate of the y coordinate of the centroid.\n",
    "        - max_iterations: number of iterations for the centroid algorithm (default=20).\n",
    "\n",
    "        Returns:\n",
    "        - x_target_refined: refined x coordinate of the centroid.\n",
    "        - y_target_refined: refined y coordinate of the centroid.\n",
    "        \"\"\"\n",
    "        \n",
    "        for i in range(0, max_iterations):\n",
    "\n",
    "            if i == 0: # First iteration\n",
    "                x_target_previous = x_target_initial\n",
    "                y_target_previous = y_target_initial\n",
    "            else: # Use the previous iteration results as new starting point\n",
    "                x_target_previous = x_target_refined\n",
    "                y_target_previous = y_target_refined\n",
    "            \n",
    "            # 2D Array with the distance of each pixel from the target star\n",
    "            target_distance = np.sqrt((self.X-x_target_previous)**2 + (self.Y-y_target_previous)**2)\n",
    "\n",
    "            # Creation of the annulus as a 2D boolean array\n",
    "            annulus_selection = (target_distance < self.sky_inner_radius)\n",
    "\n",
    "            # Weighted sum of coordinates\n",
    "            weighted_X = np.sum(science_frame[annulus_selection]*self.X[annulus_selection])\n",
    "            weighted_Y = np.sum(science_frame[annulus_selection]*self.Y[annulus_selection])\n",
    "\n",
    "            # Sum of the weights\n",
    "            total_flux = np.sum(science_frame[annulus_selection])\n",
    "\n",
    "            # Refined determination of coordinates\n",
    "            x_target_refined = weighted_X / total_flux\n",
    "            y_target_refined = weighted_Y / total_flux\n",
    "\n",
    "            precent_variance_x = (x_target_refined - x_target_previous)/(x_target_previous)*100\n",
    "            percent_variance_y = (y_target_refined - y_target_previous)/(y_target_previous)*100\n",
    "\n",
    "            if np.abs(precent_variance_x)<0.1 and np.abs(percent_variance_y)<0.1:\n",
    "                break\n",
    "        \n",
    "        return x_target_refined, y_target_refined\n",
    "\n",
    "\n",
    "    def aperture_photometry(self, sky_inner_radius, sky_outer_radius, aperture_radius, x_initial, y_initial):\n",
    "\n",
    "        # Aperture Photometry Parameters\n",
    "        self.sky_inner_radius = sky_inner_radius\n",
    "        self.sky_outer_radius = sky_outer_radius\n",
    "        self.aperture_radius = aperture_radius\n",
    "        self.x_initial = x_initial\n",
    "        self.y_initial = y_initial\n",
    "\n",
    "        # Array Initialization for HEADER Parameters\n",
    "        self.airmass = np.empty(self.science_size)\n",
    "        self.exptime = np.empty(self.science_size)\n",
    "        self.julian_date = np.epmty(self.science_size)\n",
    "\n",
    "\n",
    "        for i, science_name in enumerate(self.science_list):\n",
    "            # Open the i-th fits file\n",
    "            science_fits = fits.open(self.science_path +  science_name)\n",
    "\n",
    "            self.airmass[i] = science_fits[0].header['AIRMASS']\n",
    "            self.exptime[i] = science_fits[0].header['EXPTIME']\n",
    "            self.julian_date[i] = science_fits[0].header['JD']\n",
    "\n",
    "            # Save the i-th flux in science_data\n",
    "            science_data = science_fits[0].data * self.gain # Viene sovrascritto ad ogni iterazione quindi va salvato prima della fine del ciclo\n",
    "            science_fits.close()\n",
    "\n",
    "            # Call the method to correct the frame for bias and flat.\n",
    "            science_corrected, science_corrected_error = self.correct_science_frame(science_data)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
